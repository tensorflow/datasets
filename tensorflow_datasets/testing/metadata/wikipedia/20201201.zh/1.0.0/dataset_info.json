{
  "citation": "@ONLINE {wikidump,\n    author = \"Wikimedia Foundation\",\n    title  = \"Wikimedia Downloads\",\n    url    = \"https://dumps.wikimedia.org\"\n}",
  "configDescription": "Wikipedia dataset for zh, parsed from 20201201 dump.",
  "configName": "20201201.zh",
  "description": "Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).",
  "downloadSize": "2199432526",
  "location": {
    "urls": [
      "https://dumps.wikimedia.org"
    ]
  },
  "moduleName": "tensorflow_datasets.text.wikipedia",
  "name": "wikipedia",
  "redistributionInfo": {
    "license": "This work is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License. To view a copy of this license, visit http://creativecommons.org/licenses/by-sa/3.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA."
  },
  "splits": [
    {
      "name": "train",
      "numBytes": "2232247917",
      "shardLengths": [
        "52199",
        "52198",
        "52199",
        "52198",
        "52199",
        "52199",
        "52198",
        "52199",
        "52199",
        "52198",
        "52199",
        "52199",
        "52198",
        "52199",
        "52198",
        "52199",
        "52199",
        "52198",
        "52199",
        "52198",
        "52199",
        "52199",
        "52198",
        "52199",
        "52199",
        "52198",
        "52199",
        "52199",
        "52198",
        "52199",
        "52198",
        "52199"
      ]
    }
  ],
  "version": "1.0.0"
}