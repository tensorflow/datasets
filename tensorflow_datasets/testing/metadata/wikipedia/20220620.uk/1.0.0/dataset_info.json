{"name":"wikipedia","description":"Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).","citation":"@ONLINE {wikidump,\n    author = \"Wikimedia Foundation\",\n    title  = \"Wikimedia Downloads\",\n    url    = \"https://dumps.wikimedia.org\"\n}","location":{"urls":["https://dumps.wikimedia.org"]},"splits":[{"name":"train","shardLengths":["27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786","27786","27785","27786","27785","27786"],"numBytes":"4466645177","filepathTemplate":"{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}"}],"version":"1.0.0","downloadSize":"1998192209","configName":"20220620.uk","configDescription":"Wikipedia dataset for uk, parsed from 20220620 dump.","moduleName":"tensorflow_datasets.text.wikipedia","fileFormat":"array_record","releaseNotes":{"1.0.0":"New split API (https://tensorflow.org/datasets/splits)"}}