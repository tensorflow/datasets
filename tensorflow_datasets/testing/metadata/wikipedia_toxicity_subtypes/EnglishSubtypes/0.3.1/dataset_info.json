{
  "citation": "@inproceedings{10.1145/3038912.3052591,\n  author = {Wulczyn, Ellery and Thain, Nithum and Dixon, Lucas},\n  title = {Ex Machina: Personal Attacks Seen at Scale},\n  year = {2017},\n  isbn = {9781450349130},\n  publisher = {International World Wide Web Conferences Steering Committee},\n  address = {Republic and Canton of Geneva, CHE},\n  url = {https://doi.org/10.1145/3038912.3052591},\n  doi = {10.1145/3038912.3052591},\n  booktitle = {Proceedings of the 26th International Conference on World Wide Web},\n  pages = {1391-1399},\n  numpages = {9},\n  keywords = {online discussions, wikipedia, online harassment},\n  location = {Perth, Australia},\n  series = {WWW '17}\n}",
  "configDescription": "\nThe comments in the WikipediaToxicitySubtypes config are from an archive of\nEnglish Wikipedia talk page comments which have been annotated by Jigsaw for\ntoxicity, as well as five toxicity subtype labels (severe toxicity, obscene,\nthreat, insult, identity_attack). The toxicity and toxicity subtype labels are\nbinary values (0 or 1) indicating whether the majority of annotators assigned\nthat attribute to the comment text. This config is a replica of the data\nreleased for the Jigsaw Toxic Comment Classification Challenge on Kaggle, with\nthe test dataset joined with the test_labels released after the competition, and\ntest data not used for scoring dropped.\n\nSee the Kaggle documentation\nhttps://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\nor https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973 for more\ndetails.\n",
  "configName": "EnglishSubtypes",
  "description": "The comments in this dataset come from an archive of Wikipedia talk page\ncomments. These have been annotated by Jigsaw for toxicity, as well as (for the\nmain config) a variety of toxicity subtypes, including severe toxicity,\nobscenity, threatening language, insulting language, and identity attacks. This\ndataset is a replica of the data released for the Jigsaw Toxic Comment\nClassification Challenge and Jigsaw Multilingual Toxic Comment Classification\ncompetition on Kaggle, with the test dataset merged with the test_labels\nreleased after the end of the competitions. Test data not used for scoring has\nbeen dropped. This dataset is released under CC0, as is the underlying comment\ntext.",
  "downloadSize": "53025584",
  "fileFormat": "array_record",
  "location": {
    "urls": [
      "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data"
    ]
  },
  "moduleName": "tensorflow_datasets.text.wikipedia_toxicity_subtypes",
  "name": "wikipedia_toxicity_subtypes",
  "releaseNotes": {
    "0.2.0": "Updated features for consistency with CivilComments dataset.",
    "0.3.0": "Added WikipediaToxicityMultilingual config.",
    "0.3.1": "Added a unique id for each comment. (For the Multilingual config, these are only unique within each split.)"
  },
  "splits": [
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "train",
      "numBytes": "96288551",
      "shardLengths": [
        "159571"
      ]
    },
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "test",
      "numBytes": "38263253",
      "shardLengths": [
        "63978"
      ]
    }
  ],
  "supervisedKeys": {
    "tuple": {
      "items": [
        {
          "featureKey": "text"
        },
        {
          "featureKey": "toxicity"
        }
      ]
    }
  },
  "version": "0.3.1"
}