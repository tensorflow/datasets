{
  "citation": "@article{allenai:arc,\n      author    = {Peter Clark  and Isaac Cowhey and Oren Etzioni and Tushar Khot and\n                    Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},\n      title     = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},\n      journal   = {arXiv:1803.05457v1},\n      year      = {2018},\n}\n@article{2020unifiedqa,\n    title={UnifiedQA: Crossing Format Boundaries With a Single QA System},\n    author={D. Khashabi and S. Min and T. Khot and A. Sabhwaral and O. Tafjord and P. Clark and H. Hajishirzi},\n    journal={arXiv preprint},\n    year={2020}\n}",
  "description": "A new dataset of 7,787 genuine grade-school level, multiple-choice science\nquestions, assembled to encourage research in advanced question-answering.\nThe dataset is partitioned into a Challenge Set and an Easy Set, where the\nformer contains only questions answered incorrectly by both a retrieval-based\nalgorithm and a word co-occurrence algorithm. We are also including a corpus\nof over 14 million science sentences relevant to the task, and an\nimplementation of three neural baseline models for this dataset.\nWe pose ARC as a challenge to the community.\n\nCompared to the original dataset, this adds context sentences obtained through\ninformation retrieval in the same way as UnifiedQA (see:\nhttps://arxiv.org/abs/2005.00700 ).",
  "downloadSize": "3855104",
  "location": {
    "urls": [
      "https://allenai.org/data/arc"
    ]
  },
  "name": "ai2_arc_with_ir",
  "splits": [
    {
      "name": "test",
      "numBytes": "1791883",
      "shardLengths": [
        "1172"
      ]
    },
    {
      "name": "train",
      "numBytes": "1688587",
      "shardLengths": [
        "1119"
      ]
    },
    {
      "name": "validation",
      "numBytes": "460600",
      "shardLengths": [
        "299"
      ]
    }
  ],
  "version": "1.0.0"
}