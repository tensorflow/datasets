{
  "citation": "@article{fleurs2022arxiv,\n  title = {FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech},\n  author = {Conneau, Alexis and Ma, Min and Khanuja, Simran and Zhang, Yu and Axelrod, Vera and Dalmia, Siddharth and Riesa, Jason and Rivera, Clara and Bapna, Ankur},\n  journal={arXiv preprint arXiv:2205.12446},\n  url = {https://arxiv.org/abs/2205.12446},\n  year = {2022},\n}\n@article{conneau2022xtreme,\n  title={XTREME-S: Evaluating Cross-lingual Speech Representations},\n  author={Conneau, Alexis and Bapna, Ankur and Zhang, Yu and Ma, Min and von Platen, Patrick and Lozhkov, Anton and Cherry, Colin and Jia, Ye and Rivera, Clara and Kale, Mihir and others},\n  journal={arXiv preprint arXiv:2203.10752},\n  year={2022}\n}",
  "configDescription": "FLEURS is the speech version of the FLORES machine translation benchmark, covering 2000 n-way parallel sentences in n=102 languages.",
  "configName": "fleurs.ceb_ph",
  "description": "FLEURS is the speech version of the FLORES machine translation benchmark, covering 2000 n-way parallel sentences in n=102 languages.\nXTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in \u201cuniversal\u201d speech representation learning.\n\nIn this version, only the FLEURS dataset is provided, which covers speech\nrecognition and speech-to-text translation.",
  "downloadSize": "2826144406",
  "fileFormat": "array_record",
  "location": {
    "urls": [
      "https://arxiv.org/abs/2205.12446"
    ]
  },
  "moduleName": "tensorflow_datasets.audio.xtreme_s.xtreme_s",
  "name": "xtreme_s",
  "releaseNotes": {
    "2.0.0": "Initial release on TFDS, FLEURS-only. Named to match version 2.0.0 on huggingface which has the same FLEURS data ( https://huggingface.co/datasets/google/xtreme_s)."
  },
  "splits": [
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "train",
      "numBytes": "4845964903",
      "shardLengths": [
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "50",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "50",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "50",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51",
        "51"
      ]
    },
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "validation",
      "numBytes": "347789169",
      "shardLengths": [
        "56",
        "56",
        "57",
        "56"
      ]
    },
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "test",
      "numBytes": "876144481",
      "shardLengths": [
        "68",
        "67",
        "68",
        "67",
        "68",
        "68",
        "67",
        "68"
      ]
    }
  ],
  "supervisedKeys": {
    "tuple": {
      "items": [
        {
          "featureKey": "audio"
        },
        {
          "featureKey": "transcription"
        }
      ]
    }
  },
  "version": "2.0.0"
}