{
  "citation": "@inproceedings{robomimic2021,\n  title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},\n  author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany\n          and Chen Wang and Rohun Kulkarni and Li Fei-Fei and Silvio Savarese\n          and Yuke Zhu and Roberto Mart\\'{i}n-Mart\\'{i}n},\n  booktitle={Conference on Robot Learning},\n  year={2021}\n}",
  "configName": "can_mg_low_dim",
  "description": "The Robomimic machine generated datasets were collected using a Soft Actor\nCritic agent trained with a dense reward.\nEach dataset consists of the agent's replay buffer.\n\nEach task has two versions: one with low dimensional observations (`low_dim`),\nand one with images (`image`).\n\nThe datasets follow the [RLDS format](https://github.com/google-research/rlds)\nto represent steps and episodes.",
  "downloadSize": "1079740536",
  "fileFormat": "tfrecord",
  "location": {
    "urls": [
      "https://arise-initiative.github.io/robomimic-web/"
    ]
  },
  "moduleName": "tensorflow_datasets.datasets.robomimic_mg.robomimic_mg_dataset_builder",
  "name": "robomimic_mg",
  "releaseNotes": {
    "1.0.0": "Initial release."
  },
  "splits": [
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "train",
      "numBytes": "731598178",
      "shardLengths": [
        "488",
        "487",
        "487",
        "488",
        "488",
        "487",
        "487",
        "488"
      ]
    }
  ],
  "version": "1.0.0"
}