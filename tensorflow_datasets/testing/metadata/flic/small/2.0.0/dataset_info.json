{
  "citation": "@inproceedings{modec13,\n    title={MODEC: Multimodal Decomposable Models for Human Pose Estimation},\n    author={Sapp, Benjamin and Taskar, Ben},\n    booktitle={In Proc. CVPR},\n    year={2013},\n  }",
  "configDescription": "Uses 5003 examples used in CVPR13 MODEC paper.",
  "configName": "small",
  "description": "From the paper: We collected a 5003 image dataset automatically from popular\nHollywood movies. The images were obtained by running a state-of-the-art person\ndetector on every tenth frame of 30 movies. People detected with high confidence\n(roughly 20K candidates) were then sent to the crowdsourcing marketplace Amazon\nMechanical Turk to obtain groundtruthlabeling. Each image was annotated by five\nTurkers for $0.01 each to label 10 upperbody joints. The median-of-five labeling\nwas taken in each image to be robust to outlier annotation. Finally, images were\nrejected manually by us if the person was occluded or severely non-frontal. We\nset aside 20% (1016 images) of the data for testing.",
  "downloadSize": "300257553",
  "fileFormat": "array_record",
  "location": {
    "urls": [
      "https://bensapp.github.io/flic-dataset.html"
    ]
  },
  "moduleName": "tensorflow_datasets.image.flic",
  "name": "flic",
  "splits": [
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "train",
      "numBytes": "263790217",
      "shardLengths": [
        "1994",
        "1993"
      ]
    },
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "test",
      "numBytes": "69597430",
      "shardLengths": [
        "1016"
      ]
    }
  ],
  "version": "2.0.0"
}