{
  "citation": "@article{DBLP:journals/corr/QinL13,\n  author    = {Tao Qin and Tie{-}Yan Liu},\n  title     = {Introducing {LETOR} 4.0 Datasets},\n  journal   = {CoRR},\n  volume    = {abs/1306.2597},\n  year      = {2013},\n  url       = {http://arxiv.org/abs/1306.2597},\n  timestamp = {Mon, 01 Jul 2013 20:31:25 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/QinL13},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}",
  "configName": "30k_fold3",
  "description": "MSLR-WEB are two large-scale Learning-to-Rank datasets released by Microsoft\nResearch. The first dataset (called \"30k\") contains 30,000 queries and the\nsecond dataset (called \"10k\") contains 10,000 queries. Each dataset consists of\nquery-document pairs represented as feature vectors and corresponding relevance\njudgment labels.\n\nYou can specify whether to use the \"10k\" or \"30k\" version of the dataset, and a\ncorresponding fold, as follows:\n\n```python\nds = tfds.load(\"mslr_web/30k_fold1\")\n```\n\nIf only `mslr_web` is specified, the `mslr_web/10k_fold1` option is selected by\ndefault:\n\n```python\n# This is the same as `tfds.load(\"mslr_web/10k_fold1\")`\nds = tfds.load(\"mslr_web\")\n```",
  "downloadSize": "3849406307",
  "fileFormat": "tfrecord",
  "location": {
    "urls": [
      "https://www.microsoft.com/en-us/research/project/mslr/"
    ]
  },
  "moduleName": "tensorflow_datasets.ranking.mslr_web.mslr_web",
  "name": "mslr_web",
  "splits": [
    {
      "name": "train",
      "numBytes": "750646835",
      "shardLengths": [
        "2365",
        "2365",
        "2364",
        "2365",
        "2365",
        "2364",
        "2365",
        "2365"
      ]
    },
    {
      "name": "vali",
      "numBytes": "250808503",
      "shardLengths": [
        "3154",
        "3153"
      ]
    },
    {
      "name": "test",
      "numBytes": "249878607",
      "shardLengths": [
        "3153",
        "3153"
      ]
    }
  ],
  "version": "1.0.0"
}