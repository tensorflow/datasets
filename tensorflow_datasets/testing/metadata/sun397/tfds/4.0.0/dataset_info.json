{"name":"sun397","description":"The database contains 108,753 images of 397 categories, used in the\nScene UNderstanding (SUN) benchmark. The number of images varies across\ncategories, but there are at least 100 images per category.\n\nSeveral configs of the dataset are made available through TFDS:\n- A custom (random) partition of the whole dataset with 76,128 training images,\n  10,875 validation images and 21,750 test images. Images have been resized to\n  have at most 120,000 pixels, and encoded as JPEG with quality of 72.\n- \"standard-part1-120k\", \"standard-part2-120k\", ..., \"standard-part10-120k\":\n  Each of the 10 official train/test partitions with 50 images per class in each\n  split. Images have been resized to have at most 120,000 pixels, and encoded\n  as JPEG with quality of 72.\n","citation":"@INPROCEEDINGS{Xiao:2010,\nauthor={J. {Xiao} and J. {Hays} and K. A. {Ehinger} and A. {Oliva} and A. {Torralba}},\nbooktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\ntitle={SUN database: Large-scale scene recognition from abbey to zoo},\nyear={2010},\nvolume={},\nnumber={},\npages={3485-3492},\nkeywords={computer vision;human factors;image classification;object recognition;visual databases;SUN database;large-scale scene recognition;abbey;zoo;scene categorization;computer vision;scene understanding research;scene category;object categorization;scene understanding database;state-of-the-art algorithms;human scene classification performance;finer-grained scene representation;Sun;Large-scale systems;Layout;Humans;Image databases;Computer vision;Anthropometry;Bridges;Legged locomotion;Spatial databases}, \ndoi={10.1109/CVPR.2010.5539970},\nISSN={1063-6919},\nmonth={June},}\n","sizeInBytes":"39095590629","location":{"urls":["https://vision.princeton.edu/projects/2010/SUN/"]},"schema":{"feature":[{"name":"file_name","type":"BYTES"},{"name":"image","type":"INT","shape":{"dim":[{"size":"-1"},{"size":"-1"},{"size":"3"}]}},{"name":"label","type":"INT"}]},"splits":[{"name":"test","numShards":"1","statistics":{"numExamples":"21750","features":[{"name":"file_name","type":"BYTES","bytesStats":{"commonStats":{"numNonMissing":"21750"}}},{"name":"image","numStats":{"commonStats":{"numNonMissing":"21750"},"max":255}},{"name":"label","numStats":{"commonStats":{"numNonMissing":"21750"},"max":396}}]},"shardLengths":["1359","1360","1359","1360","1359","1359","1360","1359","1359","1360","1359","1360","1359","1359","1360","1359"]},{"name":"train","numShards":"1","statistics":{"numExamples":"76128","features":[{"name":"file_name","type":"BYTES","bytesStats":{"commonStats":{"numNonMissing":"76128"}}},{"name":"image","numStats":{"commonStats":{"numNonMissing":"76128"},"max":255}},{"name":"label","numStats":{"commonStats":{"numNonMissing":"76128"},"max":396}}]},"shardLengths":["2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379","2379"]},{"name":"validation","numShards":"1","statistics":{"numExamples":"10875","features":[{"name":"file_name","type":"BYTES","bytesStats":{"commonStats":{"numNonMissing":"10875"}}},{"name":"image","numStats":{"commonStats":{"numNonMissing":"10875"},"max":255}},{"name":"label","numStats":{"commonStats":{"numNonMissing":"10875"},"max":396}}]},"shardLengths":["1359","1360","1359","1360","1359","1359","1360","1359"]}],"version":"4.0.0","fileFormat":"array_record"}