{
  "citation": "@article{DBLP:journals/corr/abs-1903-04561,\n  author    = {Daniel Borkan and\n               Lucas Dixon and\n               Jeffrey Sorensen and\n               Nithum Thain and\n               Lucy Vasserman},\n  title     = {Nuanced Metrics for Measuring Unintended Bias with Real Data for Text\n               Classification},\n  journal   = {CoRR},\n  volume    = {abs/1903.04561},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1903.04561},\n  archivePrefix = {arXiv},\n  eprint    = {1903.04561},\n  timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-04561},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}",
  "description": "This version of the CivilComments Dataset provides access to the primary\nseven labels that were annotated by crowd workers, the toxicity and other\ntags are a value between 0 and 1 indicating the fraction of annotators that\nassigned these attributes to the comment text.\n\nThe other tags are only available for a fraction of the input examples. They\nare currently ignored for the main dataset; the CivilCommentsIdentities set\nincludes those labels, but only consists of the subset of the data with them.\nThe other attributes that were part of the original CivilComments release are\nincluded only in the raw data. See the Kaggle documentation for more details\nabout the available features.\n\nThe comments in this dataset come from an archive of the Civil Comments\nplatform, a commenting plugin for independent news sites. These public comments\nwere created from 2015 - 2017 and appeared on approximately 50 English-language\nnews sites across the world. When Civil Comments shut down in 2017, they chose\nto make the public comments available in a lasting open archive to enable future\nresearch. The original data, published on figshare, includes the public comment\ntext, some associated metadata such as article IDs, timestamps and\ncommenter-generated \"civility\" labels, but does not include user ids. Jigsaw\nextended this dataset by adding additional labels for toxicity and identity\nmentions. This data set is an exact replica of the data released for the\nJigsaw Unintended Bias in Toxicity Classification Kaggle challenge. This\ndataset is released under CC0, as is the underlying comment text.",
  "downloadSize": "414947977",
  "location": {
    "urls": [
      "https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data"
    ]
  },
  "name": "civil_comments",
  "splits": [
    {
      "name": "test",
      "numBytes": "25311945",
      "shardLengths": [
        "21577"
      ]
    },
    {
      "name": "train",
      "numBytes": "477449781",
      "shardLengths": [
        "101282",
        "101283",
        "101283",
        "101282"
      ]
    },
    {
      "name": "validation",
      "numBytes": "25025931",
      "shardLengths": [
        "21293"
      ]
    }
  ],
  "supervisedKeys": {
    "input": "text",
    "output": "toxicity"
  },
  "version": "1.0.0"
}