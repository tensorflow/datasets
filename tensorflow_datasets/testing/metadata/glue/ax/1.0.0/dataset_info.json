{"name":"glue","description":"            A manually-curated evaluation dataset for fine-grained analysis of\n            system performance on a broad range of linguistic phenomena. This\n            dataset evaluates sentence understanding through Natural Language\n            Inference (NLI) problems. Use a model trained on MulitNLI to produce\n            predictions for this dataset.","citation":"\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.","sizeInBytes":"222257","location":{"urls":["https://gluebenchmark.com/diagnostics","https://gluebenchmark.com/"]},"schema":{"feature":[{"name":"hypothesis","type":"BYTES"},{"name":"idx","type":"INT"},{"name":"label","type":"INT"},{"name":"premise","type":"BYTES"}]},"splits":[{"name":"test","numShards":"1","statistics":{"numExamples":"1104","features":[{"name":"hypothesis","type":"BYTES","bytesStats":{"commonStats":{"numNonMissing":"1104"}}},{"name":"idx","numStats":{"commonStats":{"numNonMissing":"1104"},"max":1103}},{"name":"label","numStats":{"commonStats":{"numNonMissing":"1104"},"min":-1,"max":-1}},{"name":"premise","type":"BYTES","bytesStats":{"commonStats":{"numNonMissing":"1104"}}}]},"shardLengths":["1104"]}],"version":"1.0.0","fileFormat":"array_record"}