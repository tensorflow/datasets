{
  "citation": "@misc{fu2020d4rl,\n    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},\n    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},\n    year={2020},\n    eprint={2004.07219},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}",
  "configDescription": "See more details about the task and its versions in https://github.com/rail-berkeley/d4rl/wiki/Tasks#gym",
  "configName": "v1-random",
  "description": "D4RL is an open-source benchmark for offline reinforcement learning. It provides\nstandardized environments and datasets for training and benchmarking algorithms.\n\nThe datasets follow the [RLDS format](https://github.com/google-research/rlds)\nto represent steps and episodes.",
  "downloadSize": "152241884",
  "fileFormat": "array_record",
  "location": {
    "urls": [
      "https://sites.google.com/view/d4rl/home"
    ]
  },
  "moduleName": "tensorflow_datasets.d4rl.d4rl_mujoco_halfcheetah.d4rl_mujoco_halfcheetah",
  "name": "d4rl_mujoco_halfcheetah",
  "releaseNotes": {
    "1.0.0": "Initial release.",
    "1.0.1": "Support for episode and step metadata, and unification of the reward shape across all the configs.",
    "1.1.0": "Added is_last.",
    "1.2.0": "Updated to take into account the next observation."
  },
  "splits": [
    {
      "filepathTemplate": "{DATASET}-{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}",
      "name": "train",
      "numBytes": "179498000",
      "shardLengths": [
        "500",
        "500"
      ]
    }
  ],
  "version": "1.2.0"
}