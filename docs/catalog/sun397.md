<div itemscope itemtype="http://schema.org/Dataset">
  <div itemscope itemprop="includedInDataCatalog" itemtype="http://schema.org/DataCatalog">
    <meta itemprop="name" content="TensorFlow Datasets" />
  </div>
  <meta itemprop="name" content="sun397" />
  <meta itemprop="description" content="The database contains 108,753 images of 397 categories, used in the&#10;Scene UNderstanding (SUN) benchmark. The number of images varies across&#10;categories, but there are at least 100 images per category.&#10;&#10;Several configs of the dataset are made available through TFDS:&#10;- A custom (random) partition of the whole dataset with 76,128 training images,&#10;  10,875 validation images and 21,750 test images. Images have been resized to&#10;  have at most 120,000 pixels, and encoded as JPEG with quality of 72.&#10;- &quot;standard-part1-120k&quot;, &quot;standard-part2-120k&quot;, ..., &quot;standard-part10-120k&quot;:&#10;  Each of the 10 official train/test partitions with 50 images per class in each&#10;  split. Images have been resized to have at most 120,000 pixels, and encoded&#10;  as JPEG with quality of 72.&#10;" />
  <meta itemprop="url" content="https://www.tensorflow.org/datasets/catalog/sun397" />
  <meta itemprop="sameAs" content="https://vision.princeton.edu/projects/2010/SUN/" />
</div>

# `sun397`

The database contains 108,753 images of 397 categories, used in the Scene
UNderstanding (SUN) benchmark. The number of images varies across categories,
but there are at least 100 images per category.

Several configs of the dataset are made available through TFDS: - A custom
(random) partition of the whole dataset with 76,128 training images, 10,875
validation images and 21,750 test images. Images have been resized to have at
most 120,000 pixels, and encoded as JPEG with quality of 72. -
"standard-part1-120k", "standard-part2-120k", ..., "standard-part10-120k": Each
of the 10 official train/test partitions with 50 images per class in each split.
Images have been resized to have at most 120,000 pixels, and encoded as JPEG
with quality of 72.

*   URL:
    [https://vision.princeton.edu/projects/2010/SUN/](https://vision.princeton.edu/projects/2010/SUN/)
*   `DatasetBuilder`:
    [`tfds.image.sun.Sun397`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/sun.py)

`sun397` is configured with `tfds.image.sun.Sun397Config` and has the following
configurations predefined (defaults to the first one):

*   `tfds` (`v4.0.0`) (`Size: 36.41 GiB`): TFDS partition with random
    train/validation/test splits with 70%/10%/20% of the images, respectively.
    Images are resized to have at most 120,000 pixels, and are compressed with
    72 JPEG quality.

*   `standard-part1-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 1. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part2-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 2. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part3-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 3. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part4-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 4. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part5-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 5. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part6-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 6. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part7-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 7. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part8-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 8. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part9-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 9. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

*   `standard-part10-120k` (`v4.0.0`) (`Size: 36.41 GiB`): Train and test splits
    from the official partition number 10. Images are resized to have at most
    120,000 pixels, and compressed with 72 JPEG quality.

## `sun397/tfds`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part1-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part2-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part3-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part4-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part5-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part6-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part7-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part8-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part9-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## `sun397/standard-part10-120k`

```python
FeaturesDict({
    'file_name': Text(shape=(), dtype=tf.string),
    'image': Image(shape=(None, None, 3), dtype=tf.uint8),
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=397),
})
```

## Statistics

Split | Examples
:---- | -------:
ALL   | 39,700
TRAIN | 19,850
TEST  | 19,850

## Urls

*   [https://vision.princeton.edu/projects/2010/SUN/](https://vision.princeton.edu/projects/2010/SUN/)

## Supervised keys (for `as_supervised=True`)
`None`

## Citation

```
@INPROCEEDINGS{Xiao:2010,
author={J. {Xiao} and J. {Hays} and K. A. {Ehinger} and A. {Oliva} and A. {Torralba}},
booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
title={SUN database: Large-scale scene recognition from abbey to zoo},
year={2010},
volume={},
number={},
pages={3485-3492},
keywords={computer vision;human factors;image classification;object recognition;visual databases;SUN database;large-scale scene recognition;abbey;zoo;scene categorization;computer vision;scene understanding research;scene category;object categorization;scene understanding database;state-of-the-art algorithms;human scene classification performance;finer-grained scene representation;Sun;Large-scale systems;Layout;Humans;Image databases;Computer vision;Anthropometry;Bridges;Legged locomotion;Spatial databases},
doi={10.1109/CVPR.2010.5539970},
ISSN={1063-6919},
month={June},}
```

--------------------------------------------------------------------------------
